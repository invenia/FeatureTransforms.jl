var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#Transforms","page":"API","title":"Transforms","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Transform\nHoD\nPower\nPeriodic\nAbstractScaling\nMeanStdScaling\nIdentityScaling\nLinearCombination\nOneHotEncoding","category":"page"},{"location":"api/#FeatureTransforms.Transform","page":"API","title":"FeatureTransforms.Transform","text":"Transform\n\nAbstract supertype for all feature Transforms.\n\n\n\n\n\n","category":"type"},{"location":"api/#FeatureTransforms.HoD","page":"API","title":"FeatureTransforms.HoD","text":"HoD <: Transform\n\nGet the hour of day corresponding to the data.\n\n\n\n\n\n","category":"type"},{"location":"api/#FeatureTransforms.Power","page":"API","title":"FeatureTransforms.Power","text":"Power(exponent) <: Transform\n\nRaise the data by the given exponent.\n\n\n\n\n\n","category":"type"},{"location":"api/#FeatureTransforms.Periodic","page":"API","title":"FeatureTransforms.Periodic","text":"Periodic{P, S}(f, period::P, [phase_shift::S]) <: Transform\n\nApplies a periodic function f with provided period and phase_shift to the data.\n\nThe period and phase_shift must have the same supertype of Real or Period, depending on whether the data is Real or TimeType respectively.\n\nnote: Note\nFor TimeType data, the result will change depending on the type of period given, even if the same amount of time is described. Example: Week(1) vs Second(Week(1)); the former starts the period on the most recent Monday, while the latter starts the period on the most recent multiple of 604800 seconds since time 0.\n\nFields\n\nf::Union{typeof(cos), typeof(sin)}: the periodic function\nperiod::Union{Real, Period}: the function period. Must be strictly positive.\nphase_shift::Union{Real, Period} (optional): adjusts the phase of the periodic function, measured in the same units as the input. Increasing the value translates the function to the right, toward higher/later input values.\n\n\n\n\n\n","category":"type"},{"location":"api/#FeatureTransforms.AbstractScaling","page":"API","title":"FeatureTransforms.AbstractScaling","text":"AbstractScaling <: Transform\n\nLinearly scale the data as ax + b, according to some statistics a and b.\n\n\n\n\n\n","category":"type"},{"location":"api/#FeatureTransforms.MeanStdScaling","page":"API","title":"FeatureTransforms.MeanStdScaling","text":"MeanStdScaling(mean, std) <: AbstractScaling\n\nLinearly scale the data by a statistical mean and standard deviation std. This is also known as standardization, or the Z score transform. Once computed, the statistics of a MeanStdScaling are immutable.\n\nCan take a precomputed mean and std as arguments, or compute them from data.\n\nArguments\n\nmean::NamedTuple: tuple of mean values, named by the scope of values it applies to. (all=μ, ) will apply to all data; (1=μ1, 2=μ2) for AbstractArray data will apply μ1 to the first slice and μ2 to the second slice; (a=μ1, b=μ2) for Table data will apply μ1 to column a and μ2 to column b.\nstd::NamedTuple: similar to mean but for standard deviation values.\n\nKeyword arguments to apply\n\ninverse=true: inverts the scaling (e.g. to reconstruct the unscaled data)\neps=1e-3: replaces all 0 values in std before scaling (if inverse=false)\n\n\n\n\n\n","category":"type"},{"location":"api/#FeatureTransforms.IdentityScaling","page":"API","title":"FeatureTransforms.IdentityScaling","text":"IdentityScaling <: AbstractScaling\n\nRepresents the no-op scaling which simply returns the data it is applied on.\n\n\n\n\n\n","category":"type"},{"location":"api/#FeatureTransforms.LinearCombination","page":"API","title":"FeatureTransforms.LinearCombination","text":"LinearCombination(coefficients) <: Transform\n\nCalculate the linear combination using the vector coefficients passed in.\n\n\n\n\n\n","category":"type"},{"location":"api/#FeatureTransforms.OneHotEncoding","page":"API","title":"FeatureTransforms.OneHotEncoding","text":"OneHotEncoding{R<:Real} <: Transform\n\nOne-hot encode the categorical value for each target element.\n\nConstruct a n-by-p binary matrix, given a Vector of target data x (of length n) and a Vector of all unique possible values in x (of length p).\n\nThe element [i, j] is true if the i^th target in x corresponds to the j^th possible value and false otherwise. Note that Rcan be specified to determine the return type of results. It defaults to a Matrix of Bools.\n\nNote that this Transform does not support specifying dims other than : (all dims) because it is a one-to-many transform (for example a Vector input produces a Matrix output).\n\n\n\n\n\n","category":"type"},{"location":"api/#Applying-Transforms","page":"API","title":"Applying Transforms","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"FeatureTransforms.apply\nFeatureTransforms.apply!\nFeatureTransforms.transform!\nFeatureTransforms.transform","category":"page"},{"location":"api/#FeatureTransforms.apply","page":"API","title":"FeatureTransforms.apply","text":"apply(data::T, ::Transform; kwargs...)\n\nApplies the Transform to the data. New transforms should usually only extend _apply which this method delegates to.\n\nWhere necessary, this should be extended for new data types T.\n\n\n\n\n\n","category":"function"},{"location":"api/#FeatureTransforms.apply!","page":"API","title":"FeatureTransforms.apply!","text":"apply!(data::T, ::Transform; kwargs...) -> T\n\nApplies the Transform mutating the input data. This method delegates to apply under the hood so does not need to be defined separately.\n\nIf Transform does not support mutation, this method will error.\n\n\n\n\n\n","category":"function"},{"location":"api/#FeatureTransforms.transform!","page":"API","title":"FeatureTransforms.transform!","text":"transform!(::T, data)\n\nDefines the feature engineering pipeline for some type T, which comprises a collection of Transforms to be peformed on the data.\n\ntransform! should be overloaded for custom types T that require feature engineering.\n\n\n\n\n\n","category":"function"},{"location":"api/#FeatureTransforms.transform","page":"API","title":"FeatureTransforms.transform","text":"transform(::T, data)\n\nNon-mutating version of transform!.\n\n\n\n\n\n","category":"function"},{"location":"transforms/#about-transforms","page":"Transforms","title":"Transforms","text":"","category":"section"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"A Transform defines a transformation of data, for example scaling, periodic functions, linear combination, one-hot encoding, etc.","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"DocTestSetup = quote\n    using DataFrames\n    using Dates\n    using FeatureTransforms\nend","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"Usually, a Transform has one or more parameters. For example, we can define a squaring operation (i.e. raise to the power of 2):","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"julia> p = Power(2);","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"This transformation can be applied to data x as follows:","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"julia> x = [1.0, 2.0, 3.0];\n\njulia> FeatureTransforms.apply(x, p)\n3-element Array{Float64,1}:\n 1.0\n 4.0\n 9.0","category":"page"},{"location":"transforms/#Applying-a-Transform","page":"Transforms","title":"Applying a Transform","text":"","category":"section"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"There are three main ways to apply a Transform - suppose it is called t:","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"Transforms.apply(data, t; kwargs...) is non-mutating, returning the transformed data without modifying the original data.\nt(data; kwargs...) is equivalent to Transforms.apply(data, t; kwargs...)\nTransforms.apply!(data, t; kwargs...) is mutating, returning the modified data with the same type.","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"A single Transform can be applied to different data types and in different ways. The two main data types supported are AbstractArrays and Tables.","category":"page"},{"location":"transforms/#AbstractArray-data","page":"Transforms","title":"AbstractArray data","text":"","category":"section"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"For AbstractArray data, some Transforms support a dims keyword argument in their apply methods. This will apply the Transform to slices of the array along dimensions determined by dims. For example, given a Matrix, dims=1 applies to each column, and dims=2 applies to each row. This convention is similar to Statistics.mean(M; dims=2) returning the mean of each row in matrix M.","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"julia> M = [0.0 0.0; -0.5 1.0; 0.5 2.0];\n\njulia> scaling = MeanStdScaling(M; dims=1);\n\njulia> FeatureTransforms.apply(M, scaling; dims=1)\n3×2 Array{Float64,2}:\n  0.0  -1.0\n -1.0   0.0\n  1.0   1.0","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"Note that some Transforms have restrictions on how they can be applied once constructed. For instance, MeanStdScaling stores the mean and standard deviation of some data for specified dimensions (for arrays) or columns (for tables). So MeanStdScaling should only be applied to the same data type and along the same dimensions or subset of columns specified in construction.","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"We can also provide the inds keyword to apply the Transform to certain indices along the array slices. For example, to only scale every odd row:","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"julia> FeatureTransforms.apply(M, scaling; dims=1, inds=1:2:size(M, 1))\n2×2 Array{Float64,2}:\n 0.0  -1.0\n 1.0   1.0","category":"page"},{"location":"transforms/#Table-data","page":"Transforms","title":"Table data","text":"","category":"section"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"For Table data, all Transforms support a cols keyword argument in their apply methods. This applies the transform to the specified columns, or all columns if none are specified. Using cols, we can apply different transformations to different kinds of data from the same table. For example:","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"julia> df = DataFrame(\n           :time => DateTime(2021, 2, 27, 12):Hour(1):DateTime(2021, 2, 27, 14),\n           :temperature_A => [18.1, 19.5, 21.1],\n           :temperature_B => [16.2, 17.2, 17.5],\n       );\n\njulia> feature_df = DataFrame(\n           :hour_of_day => FeatureTransforms.apply(df, HoD(); cols=:time),\n           :aggregate_temperature => FeatureTransforms.apply(df, LinearCombination([0.5, 0.5]); cols=[:temperature_A, :temperature_B])\n       )\n3×2 DataFrame\n│ Row │ hour_of_day │ aggregate_temperature │\n│     │ Int64       │ Float64               │\n├─────┼─────────────┼───────────────────────┤\n│ 1   │ 12          │ 17.15                 │\n│ 2   │ 13          │ 18.35                 │\n│ 3   │ 14          │ 19.3                  │","category":"page"},{"location":"transforms/","page":"Transforms","title":"Transforms","text":"DocTestSetup = Nothing","category":"page"},{"location":"examples/#examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"In the following example, we will imagine we are training a model to predict the temperature and humidity in a city for each hour.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"DocTestSetup = quote\n    using CSV\n    using DataFrames\n    using Dates\n    using FeatureTransforms\n\n    df = DataFrame(CSV.File(joinpath(dirname(pathof(FeatureTransforms)), \"../docs/src/assets/weather.csv\")))\nend","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"First we load some hourly weather data:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"julia> using CSV, FeatureTransforms\n\njulia> df = DataFrame(CSV.File(joinpath(dirname(pathof(FeatureTransforms)), \"../docs/src/assets/weather.csv\")))\n24×3 DataFrame\n│ Row │ time                │ temperature │ humidity │\n│     │ DateTime            │ Float64     │ Float64  │\n├─────┼─────────────────────┼─────────────┼──────────┤\n│ 1   │ 2018-09-10T00:00:00 │ 10.55       │ 93.7506  │\n│ 2   │ 2018-09-10T01:00:00 │ 9.45001     │ 96.1146  │\n│ 3   │ 2018-09-10T02:00:00 │ 8.85        │ 94.7647  │\n│ 4   │ 2018-09-10T03:00:00 │ 8.85        │ 92.3957  │\n│ 5   │ 2018-09-10T04:00:00 │ 8.35        │ 92.656   │\n│ 6   │ 2018-09-10T05:00:00 │ 8.35        │ 97.2668  │\n│ 7   │ 2018-09-10T06:00:00 │ 7.74999     │ 100.241  │\n│ 8   │ 2018-09-10T07:00:00 │ 8.85        │ 96.1578  │\n│ 9   │ 2018-09-10T08:00:00 │ 11.65       │ 89.1578  │\n│ 10  │ 2018-09-10T09:00:00 │ 13.85       │ 83.241   │\n│ 11  │ 2018-09-10T10:00:00 │ 16.15       │ 77.3999  │\n│ 12  │ 2018-09-10T11:00:00 │ 17.75       │ 69.7129  │\n│ 13  │ 2018-09-10T12:00:00 │ 18.85       │ 65.0906  │\n│ 14  │ 2018-09-10T13:00:00 │ 19.95       │ 59.1535  │\n│ 15  │ 2018-09-10T14:00:00 │ 21.15       │ 55.1354  │\n│ 16  │ 2018-09-10T15:00:00 │ 21.65       │ 54.9058  │\n│ 17  │ 2018-09-10T16:00:00 │ 21.65       │ 54.5112  │\n│ 18  │ 2018-09-10T17:00:00 │ 21.15       │ 56.8442  │\n│ 19  │ 2018-09-10T18:00:00 │ 19.95       │ 60.2864  │\n│ 20  │ 2018-09-10T19:00:00 │ 18.35       │ 64.7786  │\n│ 21  │ 2018-09-10T20:00:00 │ 16.65       │ 70.7941  │\n│ 22  │ 2018-09-10T21:00:00 │ 14.95       │ 77.3468  │\n│ 23  │ 2018-09-10T22:00:00 │ 13.85       │ 83.0855  │\n│ 24  │ 2018-09-10T23:00:00 │ 12.75       │ 86.9574  │","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"We want to create some data features based on the time of day. One way to do this is with the Periodic transform, specifying a period of 1 day:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"julia> df[:hour_of_day_sin] = FeatureTransforms.apply(df, Periodic(sin, Day(1)); cols=:time);\n\njulia> feature_df = df\n24×4 DataFrame\n│ Row │ time                │ temperature │ humidity │ hour_of_day_sin │\n│     │ DateTime            │ Float64     │ Float64  │ Float64         │\n├─────┼─────────────────────┼─────────────┼──────────┼─────────────────┤\n│ 1   │ 2018-09-10T00:00:00 │ 10.55       │ 93.7506  │ 0.0             │\n│ 2   │ 2018-09-10T01:00:00 │ 9.45001     │ 96.1146  │ 0.258819        │\n│ 3   │ 2018-09-10T02:00:00 │ 8.85        │ 94.7647  │ 0.5             │\n│ 4   │ 2018-09-10T03:00:00 │ 8.85        │ 92.3957  │ 0.707107        │\n│ 5   │ 2018-09-10T04:00:00 │ 8.35        │ 92.656   │ 0.866025        │\n│ 6   │ 2018-09-10T05:00:00 │ 8.35        │ 97.2668  │ 0.965926        │\n│ 7   │ 2018-09-10T06:00:00 │ 7.74999     │ 100.241  │ 1.0             │\n⋮\n│ 17  │ 2018-09-10T16:00:00 │ 21.65       │ 54.5112  │ -0.866025       │\n│ 18  │ 2018-09-10T17:00:00 │ 21.15       │ 56.8442  │ -0.965926       │\n│ 19  │ 2018-09-10T18:00:00 │ 19.95       │ 60.2864  │ -1.0            │\n│ 20  │ 2018-09-10T19:00:00 │ 18.35       │ 64.7786  │ -0.965926       │\n│ 21  │ 2018-09-10T20:00:00 │ 16.65       │ 70.7941  │ -0.866025       │\n│ 22  │ 2018-09-10T21:00:00 │ 14.95       │ 77.3468  │ -0.707107       │\n│ 23  │ 2018-09-10T22:00:00 │ 13.85       │ 83.0855  │ -0.5            │\n│ 24  │ 2018-09-10T23:00:00 │ 12.75       │ 86.9574  │ -0.258819       │","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Now suppose we want to use the first 22 hours as training data and the last 2 hours as test data. Our input features are the temperature, humidity, and periodic encodings for the current hour, and the outputs to predict are the temperature and humidity for the next hour. ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"julia> train_df = feature_df[1:end-2, :];\n\njulia> test_df = feature_df[end-1:end, :];\n\njulia> input_cols = [:hour_of_day_sin, :temperature, :humidity];\n\njulia> output_cols = [:temperature, :humidity];","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"For many models it is helpful to normalize the training data. We can use MeanStdScaling for that purpose. Note that the order of columns to normalise does not matter.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"julia> scaling = MeanStdScaling(train_df; cols=input_cols);\n\njulia> FeatureTransforms.apply!(train_df, scaling; cols=input_cols)\n22×4 DataFrame\n│ Row │ time                │ temperature │ humidity     │ hour_of_day_sin │\n│     │ DateTime            │ Float64     │ Float64      │ Float64         │\n├─────┼─────────────────────┼─────────────┼──────────────┼─────────────────┤\n│ 1   │ 2018-09-10T00:00:00 │ -0.809968   │ 0.986439     │ -0.0462951      │\n│ 2   │ 2018-09-10T01:00:00 │ -1.02165    │ 1.12862      │ 0.301093        │\n│ 3   │ 2018-09-10T02:00:00 │ -1.13711    │ 1.04744      │ 0.624808        │\n│ 4   │ 2018-09-10T03:00:00 │ -1.13711    │ 0.904945     │ 0.902788        │\n│ 5   │ 2018-09-10T04:00:00 │ -1.23332    │ 0.920599     │ 1.11609         │\n│ 6   │ 2018-09-10T05:00:00 │ -1.23332    │ 1.19793      │ 1.25018         │\n│ 7   │ 2018-09-10T06:00:00 │ -1.34878    │ 1.37682      │ 1.29591         │\n⋮\n│ 15  │ 2018-09-10T14:00:00 │ 1.22983     │ -1.33616     │ -0.717398       │\n│ 16  │ 2018-09-10T15:00:00 │ 1.32604     │ -1.34997     │ -0.995378       │\n│ 17  │ 2018-09-10T16:00:00 │ 1.32604     │ -1.37371     │ -1.20868        │\n│ 18  │ 2018-09-10T17:00:00 │ 1.22983     │ -1.23338     │ -1.34277        │\n│ 19  │ 2018-09-10T18:00:00 │ 0.998903    │ -1.02634     │ -1.3885         │\n│ 20  │ 2018-09-10T19:00:00 │ 0.691009    │ -0.75615     │ -1.34277        │\n│ 21  │ 2018-09-10T20:00:00 │ 0.363876    │ -0.394332    │ -1.20868        │\n│ 22  │ 2018-09-10T21:00:00 │ 0.0367371   │ -0.000206509 │ -0.995378       │","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"We can use the same scaling transform to normalize the test data:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"julia> FeatureTransforms.apply!(test_df, scaling; cols=input_cols)\n2×4 DataFrame\n│ Row │ time                │ temperature │ humidity │ hour_of_day_sin │\n│     │ DateTime            │ Float64     │ Float64  │ Float64         │\n├─────┼─────────────────────┼─────────────┼──────────┼─────────────────┤\n│ 1   │ 2018-09-10T22:00:00 │ -0.174941   │ 0.344958 │ -0.717398       │\n│ 2   │ 2018-09-10T23:00:00 │ -0.386618   │ 0.577845 │ -0.393684       │","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Suppose we then train our model, and get a prediction for the test points as a matrix: [-0.36 0.61; -0.45 0.68]. We can scale this back to the original units of temperature and humidity by converting to a Table type (to label the columns) and using inverse scaling:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"julia> predictions = DataFrame([-0.36 0.61; -0.45 0.68], output_cols);\n\njulia> FeatureTransforms.apply!(predictions, scaling; cols=output_cols, inverse=true)\n2×2 DataFrame\n│ Row │ temperature │ humidity │\n│     │ Float64     │ Float64  │\n├─────┼─────────────┼──────────┤\n│ 1   │ 12.8883     │ 87.492   │\n│ 2   │ 12.4206     │ 88.6558  │","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"DocTestSetup = Nothing","category":"page"},{"location":"#FeatureTransforms","page":"Home","title":"FeatureTransforms","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"FeatureTransforms.jl provides utilities for performing feature engineering in machine learning pipelines. FeatureTransforms supports operations on AbstractArrays and Tables.","category":"page"},{"location":"","page":"Home","title":"Home","text":"There are three key parts of the Transforms.jl API:","category":"page"},{"location":"","page":"Home","title":"Home","text":"A Transform defines a transformation of data, for example normalisation or a periodic function.\nAn apply method applies a Transform to data, in a manner determined by the data type and specified dimensions, column names, indices, and other Transform-specific parameters.\nThe transform interface can be used to define a feature engineering pipeline, which comprises a collection of Transforms to be peformed on some data.","category":"page"},{"location":"#Getting-Started","page":"Home","title":"Getting Started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Here are some resources for getting started with FeatureTransforms.jl:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Refer to the page on Transforms to learn how they are defined and used.\nConsult the examples section for a quick guide to some typical use cases.","category":"page"}]
}
